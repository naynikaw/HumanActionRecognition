{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naynikaw/HumanActionRecognition/blob/main/I3D_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a7aeU0-ZecA"
      },
      "outputs": [],
      "source": [
        "!pip install -q imageio\n",
        "!pip install -q opencv-python\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67uasVv9Zk5R"
      },
      "outputs": [],
      "source": [
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "# Some modules to help with reading the UCF101 dataset.\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import tempfile\n",
        "import ssl\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Some modules to display an animation using imageio.\n",
        "import imageio\n",
        "from IPython import display\n",
        "\n",
        "from urllib import request  # requires python3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCdGA6LKZPFD"
      },
      "outputs": [],
      "source": [
        "# Utilities to open video files using CV2\n",
        "def crop_center_square(frame):\n",
        "  y, x = frame.shape[0:2]\n",
        "  min_dim = min(y, x)\n",
        "  start_x = (x // 2) - (min_dim // 2)\n",
        "  start_y = (y // 2) - (min_dim // 2)\n",
        "  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(224, 224)):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      frame = crop_center_square(frame)\n",
        "      frame = cv2.resize(frame, resize)\n",
        "      frame = frame[:, :, [2, 1, 0]]\n",
        "      frames.append(frame)\n",
        "\n",
        "      if len(frames) == max_frames:\n",
        "        break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  return np.array(frames) / 255.0\n",
        "\n",
        "def to_gif(images):\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('./animation.gif', converted_images, fps=25)\n",
        "  return embed.embed_file('./animation.gif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu5ht1LYaVlT"
      },
      "outputs": [],
      "source": [
        "i3d = hub.load(\"https://tfhub.dev/deepmind/i3d-kinetics-400/1\").signatures['default']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xZ_Tcsway9Q",
        "outputId": "51443d40-820d-4959-8c2e-bd1145d0a50a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abseiling', 'air drumming', 'answering questions', 'applauding', 'applying cream', 'archery', 'arm wrestling', 'arranging flowers', 'assembling computer', 'auctioning', 'baby waking up', 'baking cookies', 'balloon blowing', 'bandaging', 'barbequing', 'bartending', 'beatboxing', 'bee keeping', 'belly dancing', 'bench pressing', 'bending back', 'bending metal', 'biking through snow', 'blasting sand', 'blowing glass', 'blowing leaves', 'blowing nose', 'blowing out candles', 'bobsledding', 'bookbinding', 'bouncing on trampoline', 'bowling', 'braiding hair', 'breading or breadcrumbing', 'breakdancing', 'brush painting', 'brushing hair', 'brushing teeth', 'building cabinet', 'building shed', 'bungee jumping', 'busking', 'canoeing or kayaking', 'capoeira', 'carrying baby', 'cartwheeling', 'carving pumpkin', 'catching fish', 'catching or throwing baseball', 'catching or throwing frisbee', 'catching or throwing softball', 'celebrating', 'changing oil', 'changing wheel', 'checking tires', 'cheerleading', 'chopping wood', 'clapping', 'clay pottery making', 'clean and jerk', 'cleaning floor', 'cleaning gutters', 'cleaning pool', 'cleaning shoes', 'cleaning toilet', 'cleaning windows', 'climbing a rope', 'climbing ladder', 'climbing tree', 'contact juggling', 'cooking chicken', 'cooking egg', 'cooking on campfire', 'cooking sausages', 'counting money', 'country line dancing', 'cracking neck', 'crawling baby', 'crossing river', 'crying', 'curling hair', 'cutting nails', 'cutting pineapple', 'cutting watermelon', 'dancing ballet', 'dancing charleston', 'dancing gangnam style', 'dancing macarena', 'deadlifting', 'decorating the christmas tree', 'digging', 'dining', 'disc golfing', 'diving cliff', 'dodgeball', 'doing aerobics', 'doing laundry', 'doing nails', 'drawing', 'dribbling basketball', 'drinking', 'drinking beer', 'drinking shots', 'driving car', 'driving tractor', 'drop kicking', 'drumming fingers', 'dunking basketball', 'dying hair', 'eating burger', 'eating cake', 'eating carrots', 'eating chips', 'eating doughnuts', 'eating hotdog', 'eating ice cream', 'eating spaghetti', 'eating watermelon', 'egg hunting', 'exercising arm', 'exercising with an exercise ball', 'extinguishing fire', 'faceplanting', 'feeding birds', 'feeding fish', 'feeding goats', 'filling eyebrows', 'finger snapping', 'fixing hair', 'flipping pancake', 'flying kite', 'folding clothes', 'folding napkins', 'folding paper', 'front raises', 'frying vegetables', 'garbage collecting', 'gargling', 'getting a haircut', 'getting a tattoo', 'giving or receiving award', 'golf chipping', 'golf driving', 'golf putting', 'grinding meat', 'grooming dog', 'grooming horse', 'gymnastics tumbling', 'hammer throw', 'headbanging', 'headbutting', 'high jump', 'high kick', 'hitting baseball', 'hockey stop', 'holding snake', 'hopscotch', 'hoverboarding', 'hugging', 'hula hooping', 'hurdling', 'hurling (sport)', 'ice climbing', 'ice fishing', 'ice skating', 'ironing', 'javelin throw', 'jetskiing', 'jogging', 'juggling balls', 'juggling fire', 'juggling soccer ball', 'jumping into pool', 'jumpstyle dancing', 'kicking field goal', 'kicking soccer ball', 'kissing', 'kitesurfing', 'knitting', 'krumping', 'laughing', 'laying bricks', 'long jump', 'lunge', 'making a cake', 'making a sandwich', 'making bed', 'making jewelry', 'making pizza', 'making snowman', 'making sushi', 'making tea', 'marching', 'massaging back', 'massaging feet', 'massaging legs', \"massaging person's head\", 'milking cow', 'mopping floor', 'motorcycling', 'moving furniture', 'mowing lawn', 'news anchoring', 'opening bottle', 'opening present', 'paragliding', 'parasailing', 'parkour', 'passing American football (in game)', 'passing American football (not in game)', 'peeling apples', 'peeling potatoes', 'petting animal (not cat)', 'petting cat', 'picking fruit', 'planting trees', 'plastering', 'playing accordion', 'playing badminton', 'playing bagpipes', 'playing basketball', 'playing bass guitar', 'playing cards', 'playing cello', 'playing chess', 'playing clarinet', 'playing controller', 'playing cricket', 'playing cymbals', 'playing didgeridoo', 'playing drums', 'playing flute', 'playing guitar', 'playing harmonica', 'playing harp', 'playing ice hockey', 'playing keyboard', 'playing kickball', 'playing monopoly', 'playing organ', 'playing paintball', 'playing piano', 'playing poker', 'playing recorder', 'playing saxophone', 'playing squash or racquetball', 'playing tennis', 'playing trombone', 'playing trumpet', 'playing ukulele', 'playing violin', 'playing volleyball', 'playing xylophone', 'pole vault', 'presenting weather forecast', 'pull ups', 'pumping fist', 'pumping gas', 'punching bag', 'punching person (boxing)', 'push up', 'pushing car', 'pushing cart', 'pushing wheelchair', 'reading book', 'reading newspaper', 'recording music', 'riding a bike', 'riding camel', 'riding elephant', 'riding mechanical bull', 'riding mountain bike', 'riding mule', 'riding or walking with horse', 'riding scooter', 'riding unicycle', 'ripping paper', 'robot dancing', 'rock climbing', 'rock scissors paper', 'roller skating', 'running on treadmill', 'sailing', 'salsa dancing', 'sanding floor', 'scrambling eggs', 'scuba diving', 'setting table', 'shaking hands', 'shaking head', 'sharpening knives', 'sharpening pencil', 'shaving head', 'shaving legs', 'shearing sheep', 'shining shoes', 'shooting basketball', 'shooting goal (soccer)', 'shot put', 'shoveling snow', 'shredding paper', 'shuffling cards', 'side kick', 'sign language interpreting', 'singing', 'situp', 'skateboarding', 'ski jumping', 'skiing (not slalom or crosscountry)', 'skiing crosscountry', 'skiing slalom', 'skipping rope', 'skydiving', 'slacklining', 'slapping', 'sled dog racing', 'smoking', 'smoking hookah', 'snatch weight lifting', 'sneezing', 'sniffing', 'snorkeling', 'snowboarding', 'snowkiting', 'snowmobiling', 'somersaulting', 'spinning poi', 'spray painting', 'spraying', 'springboard diving', 'squat', 'sticking tongue out', 'stomping grapes', 'stretching arm', 'stretching leg', 'strumming guitar', 'surfing crowd', 'surfing water', 'sweeping floor', 'swimming backstroke', 'swimming breast stroke', 'swimming butterfly stroke', 'swing dancing', 'swinging legs', 'swinging on something', 'sword fighting', 'tai chi', 'taking a shower', 'tango dancing', 'tap dancing', 'tapping guitar', 'tapping pen', 'tasting beer', 'tasting food', 'testifying', 'texting', 'throwing axe', 'throwing ball', 'throwing discus', 'tickling', 'tobogganing', 'tossing coin', 'tossing salad', 'training dog', 'trapezing', 'trimming or shaving beard', 'trimming trees', 'triple jump', 'tying bow tie', 'tying knot (not on a tie)', 'tying tie', 'unboxing', 'unloading truck', 'using computer', 'using remote controller (not gaming)', 'using segway', 'vault', 'waiting in line', 'walking the dog', 'washing dishes', 'washing feet', 'washing hair', 'washing hands', 'water skiing', 'water sliding', 'watering plants', 'waxing back', 'waxing chest', 'waxing eyebrows', 'waxing legs', 'weaving basket', 'welding', 'whistling', 'windsurfing', 'wrapping present', 'wrestling', 'writing', 'yawning', 'yoga', 'zumba']\n",
            "Found 400 labels.\n"
          ]
        }
      ],
      "source": [
        "KINETICS_URL = \"https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt\"\n",
        "with request.urlopen(KINETICS_URL) as obj:\n",
        "  labels = [line.decode(\"utf-8\").strip() for line in obj.readlines()]\n",
        "print(labels)\n",
        "print(\"Found %d labels.\" % len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA0eEYfOaXkP"
      },
      "outputs": [],
      "source": [
        "def predict(sample_video):\n",
        "  # Add a batch axis to the sample video.\n",
        "  model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n",
        "\n",
        "  logits = i3d(model_input)['default'][0]\n",
        "  probabilities = tf.nn.softmax(logits)\n",
        "\n",
        "  print(\"Top 5 actions:\")\n",
        "  for i in np.argsort(probabilities)[::-1][:5]:\n",
        "    print(f\"  {labels[i]:22}: {probabilities[i] * 100:5.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9VjoBMzZph_",
        "outputId": "e9eeceb1-6bcb-4bad-e643-bda8d6b8efbe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "Sat May 21 04:21:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXreGvJUT6uy",
        "outputId": "507c300a-438f-45ed-e81d-40e3ee2dc311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet-cu110\n",
            "  Downloading mxnet_cu110-1.9.1-py3-none-manylinux2014_x86_64.whl (327.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 327.3 MB 5.9 kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu110) (1.21.6)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu110) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet-cu110\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu110-1.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mxnet-cu110"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHZ-YhXAT-UR",
        "outputId": "467d0d11-8e8e-4a52-80ad-05441d78de04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gluoncv\n",
            "  Downloading gluoncv-0.10.5.post0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.64.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.3.5)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.13)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->gluoncv) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2022.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2021.10.8)\n",
            "Installing collected packages: yacs, portalocker, autocfg, gluoncv\n",
            "Successfully installed autocfg-0.0.8 gluoncv-0.10.5.post0 portalocker-2.4.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install gluoncv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install decord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWhQ3uH_coHs",
        "outputId": "7ee875bc-03d4-41ff-d326-324c7c8c44f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting decord\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.6 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from decord) (1.21.6)\n",
            "Installing collected packages: decord\n",
            "Successfully installed decord-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usAgHFE6fCNF",
        "outputId": "af41c797-0dcf-4944-d030-0fc90fd7fbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.1` and `torch==1.11.0+cu113` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
            "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
          ]
        }
      ],
      "source": [
        "from __future__ import division\n",
        "\n",
        "import argparse, time, logging, os, sys, math\n",
        "\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import gluoncv as gcv\n",
        "from mxnet import gluon, nd, init, context\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv.data import VideoClsCustom\n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import decord"
      ],
      "metadata": {
        "id": "q-utOROserDm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND5OlS1GUNXd"
      },
      "source": [
        "Script to make train.txt file (walking:0, running:1, sitting:2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W2JOo4V1T5Jd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "with open(\"train.txt\", \"w\") as a:\n",
        "    for path, subdirs, files in os.walk(r'/content/drive/MyDrive/new/walking'):\n",
        "       for filename in files:\n",
        "         f = os.path.join(path, filename)\n",
        "         a.write(str(f) + \" \")\n",
        "         a.write(str(100) + \" \")\n",
        "         a.write(str(0) + os.linesep)\n",
        "\n",
        "    for path, subdirs, files in os.walk(r'/content/drive/MyDrive/new/running'):\n",
        "       for filename in files:\n",
        "         f = os.path.join(path, filename)\n",
        "         a.write(str(f) + \" \")\n",
        "         a.write(str(100) + \" \")\n",
        "         a.write(str(1) + os.linesep)\n",
        "\n",
        "    for path, subdirs, files in os.walk(r'/content/drive/MyDrive/new/sitting'):\n",
        "       for filename in files:\n",
        "         f = os.path.join(path, filename)\n",
        "         a.write(str(f) + \" \")\n",
        "         a.write(str(100) + \" \")\n",
        "         a.write(str(2) + os.linesep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34QHy-O5UiKn",
        "outputId": "49aab44c-6df1-4bbe-ae37-a08ac71f8f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load 60 training samples.\n"
          ]
        }
      ],
      "source": [
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "transform_train = video.VideoGroupTrainTransform(size=(224, 224), scale_ratios=[1.0, 0.8], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "per_device_batch_size = 5\n",
        "num_workers = 0\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "train_dataset = VideoClsCustom(root=os.path.expanduser('/content/drive/MyDrive/new'),\n",
        "                               setting=os.path.expanduser('/content/train.txt'),\n",
        "                               train=True,\n",
        "                               new_length=32,\n",
        "                               transform=transform_train,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True)\n",
        "print('Load %d training samples.' % len(train_dataset))\n",
        "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9LZvINEXc6k",
        "outputId": "8bbe162a-53fe-40c1-a5ed-ace68fb727bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "mx.test_utils.list_gpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRubbENHVZ3K",
        "outputId": "f135b69c-54e8-4a28-acd4-6c8e91a37750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.mxnet/models/resnet50_v1b-0ecdba34.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v1b-0ecdba34.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55344/55344 [00:00<00:00, 55692.27KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv0_weight is done with shape:  (64, 3, 5, 7, 7)\n",
            "batchnorm0_gamma is done with shape:  (64,)\n",
            "batchnorm0_beta is done with shape:  (64,)\n",
            "batchnorm0_running_mean is done with shape:  (64,)\n",
            "batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv0_weight is done with shape:  (64, 64, 3, 1, 1)\n",
            "layer1_0_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_0_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_0_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_0_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_downsample_conv0_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_downsample_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_beta is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer1_1_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_1_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_1_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_1_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_1_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_1_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_2_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_2_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_2_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_2_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_2_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_2_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer2_0_conv0_weight is done with shape:  (128, 256, 3, 1, 1)\n",
            "layer2_0_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_0_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_0_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_0_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_0_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_downsample_conv0_weight is done with shape:  (512, 256, 1, 1, 1)\n",
            "layer2_downsample_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_beta is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer2_1_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_1_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_1_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_1_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_1_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_1_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_2_conv0_weight is done with shape:  (128, 512, 3, 1, 1)\n",
            "layer2_2_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_2_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_2_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_2_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_2_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_3_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_3_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_3_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_3_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_3_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_3_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer3_0_conv0_weight is done with shape:  (256, 512, 3, 1, 1)\n",
            "layer3_0_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_0_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_0_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_0_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_0_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_downsample_conv0_weight is done with shape:  (1024, 512, 1, 1, 1)\n",
            "layer3_downsample_batchnorm0_gamma is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_beta is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_mean is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_var is done with shape:  (1024,)\n",
            "layer3_1_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_1_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_1_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_1_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_1_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_1_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_2_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_2_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_2_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_2_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_2_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_2_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_3_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_3_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_3_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_3_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_3_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_3_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_4_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_4_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_4_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_4_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_4_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_4_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_5_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_5_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_5_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_5_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_5_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_5_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer4_0_conv0_weight is done with shape:  (512, 1024, 1, 1, 1)\n",
            "layer4_0_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_0_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_0_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_0_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_0_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_downsample_conv0_weight is done with shape:  (2048, 1024, 1, 1, 1)\n",
            "layer4_downsample_batchnorm0_gamma is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_beta is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_mean is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_var is done with shape:  (2048,)\n",
            "layer4_1_conv0_weight is done with shape:  (512, 2048, 3, 1, 1)\n",
            "layer4_1_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_1_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_1_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_1_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_1_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_2_conv0_weight is done with shape:  (512, 2048, 1, 1, 1)\n",
            "layer4_2_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_2_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_2_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_2_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_2_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_var is done with shape:  (2048,)\n",
            "dense0_weight is skipped with shape:  (3, 2048)\n",
            "dense0_bias is skipped with shape:  (3,)\n",
            "Downloading /root/.mxnet/models/i3d_resnet50_v1_kinetics400-568a722e.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/i3d_resnet50_v1_kinetics400-568a722e.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 208483/208483 [00:06<00:00, 30623.21KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I3D_ResNetV1(\n",
            "  (first_stage): HybridSequential(\n",
            "    (0): Conv3D(3 -> 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "    (2): Activation(relu)\n",
            "    (3): MaxPool3D(size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  )\n",
            "  (pool2): MaxPool3D(size=(2, 1, 1), stride=(2, 1, 1), padding=(0, 0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  (res_layers): HybridSequential(\n",
            "    (0): HybridSequential(\n",
            "      (0): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        )\n",
            "        (conv1): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (relu): Activation(relu)\n",
            "        (downsample): HybridSequential(\n",
            "          (0): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=256)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        )\n",
            "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        )\n",
            "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "    )\n",
            "    (1): HybridSequential(\n",
            "      (0): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        )\n",
            "        (conv1): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (relu): Activation(relu)\n",
            "        (downsample): HybridSequential(\n",
            "          (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=512)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        )\n",
            "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        )\n",
            "        (conv1): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        )\n",
            "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "    )\n",
            "    (2): HybridSequential(\n",
            "      (0): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "        (downsample): HybridSequential(\n",
            "          (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=1024)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "    )\n",
            "    (3): HybridSequential(\n",
            "      (0): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        )\n",
            "        (conv1): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        (relu): Activation(relu)\n",
            "        (downsample): HybridSequential(\n",
            "          (0): Conv3D(1024 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=2048)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        )\n",
            "        (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (bottleneck): HybridSequential(\n",
            "          (0): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (2): Activation(relu)\n",
            "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "          (5): Activation(relu)\n",
            "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        )\n",
            "        (conv1): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "        (relu): Activation(relu)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (st_avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
            "  (head): HybridSequential(\n",
            "    (0): Dropout(p = 0.8, axes=())\n",
            "    (1): Dense(2048 -> 3, linear)\n",
            "  )\n",
            "  (fc): Dense(2048 -> 3, linear)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "net = get_model(name='i3d_resnet50_v1_custom', nclass=3)\n",
        "net.collect_params().reset_ctx(ctx)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pzjslGhpVdpY"
      },
      "outputs": [],
      "source": [
        "# Learning rate decay factor\n",
        "lr_decay = 0.1\n",
        "# Epochs where learning rate decays\n",
        "lr_decay_epoch = [40, 80, 100]\n",
        "\n",
        "# Stochastic gradient descent\n",
        "optimizer = 'sgd'\n",
        "# Set parameters\n",
        "optimizer_params = {'learning_rate': 0.001, 'wd': 0.0001, 'momentum': 0.9}\n",
        "\n",
        "# Define our trainer for net\n",
        "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "metadata": {
        "id": "LlfPYLTSboZP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_metric = mx.metric.Accuracy()\n",
        "train_history = TrainingHistory(['training-acc'])"
      ],
      "metadata": {
        "id": "tFWtefK-bqwV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 9\n",
        "lr_decay_count = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    tic = time.time()\n",
        "    train_metric.reset()\n",
        "    train_loss = 0\n",
        "\n",
        "    # Learning rate decay\n",
        "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
        "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
        "        lr_decay_count += 1\n",
        "\n",
        "    # Loop through each batch of training data\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        # AutoGrad\n",
        "        with ag.record():\n",
        "            output = []\n",
        "            for _, X in enumerate(data):\n",
        "                X = X.reshape((-1,) + X.shape[2:])\n",
        "                pred = net(X)\n",
        "                output.append(pred)\n",
        "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
        "\n",
        "        # Backpropagation\n",
        "        for l in loss:\n",
        "            l.backward()\n",
        "\n",
        "        # Optimize\n",
        "        trainer.step(batch_size)\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
        "        train_metric.update(label, output)\n",
        "\n",
        "        if i == 100:\n",
        "            break\n",
        "\n",
        "    name, acc = train_metric.get()\n",
        "\n",
        "    # Update history and print metrics\n",
        "    train_history.update([acc])\n",
        "    print('[Epoch %d] train=%f loss=%f time: %f' %\n",
        "        (epoch, acc, train_loss / (i+1), time.time()-tic))\n",
        "\n",
        "# We can plot the metric scores with:\n",
        "train_history.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "G2hxZzZ8btbq",
        "outputId": "e7bb8ae1-95ce-4380-a1b5-ad98f96b438b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0] train=0.316667 loss=1.114950 time: 55.288848\n",
            "[Epoch 1] train=0.516667 loss=1.019351 time: 19.463009\n",
            "[Epoch 2] train=0.700000 loss=0.924921 time: 17.563737\n",
            "[Epoch 3] train=0.666667 loss=0.794306 time: 17.449594\n",
            "[Epoch 4] train=0.750000 loss=0.721701 time: 17.239685\n",
            "[Epoch 5] train=0.783333 loss=0.643845 time: 17.485449\n",
            "[Epoch 6] train=0.850000 loss=0.535277 time: 17.496716\n",
            "[Epoch 7] train=0.800000 loss=0.505714 time: 16.941803\n",
            "[Epoch 8] train=0.850000 loss=0.405438 time: 17.243672\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.save_parameters(\"parameters.params\")"
      ],
      "metadata": {
        "id": "kDsG_ljXb06L"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Script to make val.txt"
      ],
      "metadata": {
        "id": "IP51rR-VaWxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "with open(\"val.txt\", \"w\") as a:\n",
        "    for path, subdirs, files in os.walk(r'/content/drive/MyDrive/new/test/walking'):\n",
        "       for filename in files:\n",
        "         f = os.path.join(path, filename)\n",
        "         a.write(str(f) + \" \")\n",
        "         a.write(str(100) + \" \")\n",
        "         a.write(str(0) + os.linesep)\n",
        "\n",
        "    for path, subdirs, files in os.walk(r'/content/drive/MyDrive/new/test/running'):\n",
        "       for filename in files:\n",
        "         f = os.path.join(path, filename)\n",
        "         a.write(str(f) + \" \")\n",
        "         a.write(str(100) + \" \")\n",
        "         a.write(str(1) + os.linesep)\n",
        "\n",
        "    for path, subdirs, files in os.walk(r'/content/drive/MyDrive/new/test/sitting'):\n",
        "       for filename in files:\n",
        "         f = os.path.join(path, filename)\n",
        "         a.write(str(f) + \" \")\n",
        "         a.write(str(100) + \" \")\n",
        "         a.write(str(2) + os.linesep)\n"
      ],
      "metadata": {
        "id": "G-Wivm0cbD4C"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference1.py --data-list val.txt --model i3d_resnet50_v1_custom --resume-params parameters.params --num-classes 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPyvU7xccwCy",
        "outputId": "5a1c359a-d887-46d2-c014-5c2aaeb9b5c8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.1` and `torch==1.11.0+cu113` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
            "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n",
            "Namespace(data_aug='v1', data_dir='', data_list='val.txt', dtype='float32', fast_temporal_stride=2, gpu_id=0, hashtag='', input_size=224, log_interval=10, logging_file='predictions.log', mode=None, model='i3d_resnet50_v1_custom', need_root=False, new_height=256, new_length=32, new_step=1, new_width=340, num_classes=3, num_crop=1, num_segments=1, resume_params='parameters.params', save_dir='./predictions', save_logits=False, save_preds=False, slow_temporal_stride=16, slowfast=False, ten_crop=False, three_crop=False, use_decord=True, use_pretrained=False, video_loader=True)\n",
            "conv0_weight is done with shape:  (64, 3, 5, 7, 7)\n",
            "batchnorm0_gamma is done with shape:  (64,)\n",
            "batchnorm0_beta is done with shape:  (64,)\n",
            "batchnorm0_running_mean is done with shape:  (64,)\n",
            "batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv0_weight is done with shape:  (64, 64, 3, 1, 1)\n",
            "layer1_0_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_0_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_0_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_0_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_downsample_conv0_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_downsample_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_beta is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer1_1_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_1_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_1_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_1_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_1_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_1_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_2_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_2_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_2_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_2_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_2_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_2_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer2_0_conv0_weight is done with shape:  (128, 256, 3, 1, 1)\n",
            "layer2_0_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_0_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_0_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_0_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_0_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_downsample_conv0_weight is done with shape:  (512, 256, 1, 1, 1)\n",
            "layer2_downsample_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_beta is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer2_1_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_1_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_1_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_1_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_1_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_1_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_2_conv0_weight is done with shape:  (128, 512, 3, 1, 1)\n",
            "layer2_2_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_2_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_2_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_2_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_2_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_3_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_3_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_3_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_3_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_3_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_3_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer3_0_conv0_weight is done with shape:  (256, 512, 3, 1, 1)\n",
            "layer3_0_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_0_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_0_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_0_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_0_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_downsample_conv0_weight is done with shape:  (1024, 512, 1, 1, 1)\n",
            "layer3_downsample_batchnorm0_gamma is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_beta is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_mean is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_var is done with shape:  (1024,)\n",
            "layer3_1_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_1_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_1_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_1_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_1_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_1_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_2_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_2_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_2_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_2_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_2_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_2_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_3_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_3_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_3_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_3_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_3_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_3_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_4_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_4_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_4_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_4_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_4_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_4_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_5_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_5_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_5_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_5_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_5_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_5_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer4_0_conv0_weight is done with shape:  (512, 1024, 1, 1, 1)\n",
            "layer4_0_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_0_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_0_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_0_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_0_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_downsample_conv0_weight is done with shape:  (2048, 1024, 1, 1, 1)\n",
            "layer4_downsample_batchnorm0_gamma is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_beta is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_mean is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_var is done with shape:  (2048,)\n",
            "layer4_1_conv0_weight is done with shape:  (512, 2048, 3, 1, 1)\n",
            "layer4_1_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_1_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_1_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_1_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_1_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_2_conv0_weight is done with shape:  (512, 2048, 1, 1, 1)\n",
            "layer4_2_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_2_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_2_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_2_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_2_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_var is done with shape:  (2048,)\n",
            "dense0_weight is skipped with shape:  (3, 2048)\n",
            "dense0_bias is skipped with shape:  (3,)\n",
            "Pre-trained model parameters.params is successfully loaded.\n",
            "Successfully built model i3d_resnet50_v1_custom\n",
            "Load 30 video samples.\n",
            "[04:58:17] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
            "0000/0030: okutama_1.1.10_Walking_95.mp4 is predicted to class running, original class walking\n",
            "0001/0030: okutama_1.1.5_Walking_55.mp4 is predicted to class walking, original class walking\n",
            "0002/0030: okutama_2.2.5_Walking_51.mp4 is predicted to class walking, original class walking\n",
            "0003/0030: ucaerial_actions1_Walking_2_0.mp4 is predicted to class walking, original class walking\n",
            "0004/0030: ucarg_person01_04_rooftop_walking.mp4 is predicted to class running, original class walking\n",
            "0005/0030: ucarg_person01_04_ground_walking.mp4 is predicted to class running, original class walking\n",
            "0006/0030: virat_VIRAT_S_010000_00_000000_000165_carrying_21.mp4 is predicted to class walking, original class walking\n",
            "0007/0030: virat_VIRAT_S_010001_01_000071_000167_carrying_43.mp4 is predicted to class sitting, original class walking\n",
            "0008/0030: virat_VIRAT_S_010208_00_000000_000049_carrying_1.mp4 is predicted to class walking, original class walking\n",
            "0009/0030: virat_VIRAT_S_050000_10_001462_001491_carrying_10.mp4 is predicted to class sitting, original class walking\n",
            "0010/0030: casia_horizontalview_p01_run_a1.mp4 is predicted to class running, original class running\n",
            "0011/0030: casia_horizontalview_p04_run_a2.mp4 is predicted to class running, original class running\n",
            "0012/0030: okutama_1.1.10_Running_93.mp4 is predicted to class walking, original class running\n",
            "0013/0030: ucarg_person02_03_rooftop_jogging.mp4 is predicted to class running, original class running\n",
            "0014/0030: ucarg_person05_04_ground_jogging.mp4 is predicted to class running, original class running\n",
            "0015/0030: ucarg_person05_04_rooftop_jogging.mp4 is predicted to class running, original class running\n",
            "0016/0030: ucarg_person06_02_rooftop_running.mp4 is predicted to class running, original class running\n",
            "0017/0030: virat_VIRAT_S_010204_04_000646_000754_running_6.mp4 is predicted to class running, original class running\n",
            "0018/0030: virat_VIRAT_S_050300_01_000148_000396_running_146.mp4 is predicted to class walking, original class running\n",
            "0019/0030: virat_VIRAT_S_050000_08_001235_001295_running_23.mp4 is predicted to class sitting, original class running\n",
            "0020/0030: okutama_1.2.6_Sitting_33.mp4 is predicted to class walking, original class sitting\n",
            "0021/0030: okutama_2.1.2_Sitting_52.mp4 is predicted to class sitting, original class sitting\n",
            "0022/0030: okutama_2.1.2_Sitting_53.mp4 is predicted to class sitting, original class sitting\n",
            "0023/0030: okutama_2.1.4_Sitting_90.mp4 is predicted to class sitting, original class sitting\n",
            "0024/0030: virat_VIRAT_S_000006_entering_vehicle_7.mp4 is predicted to class sitting, original class sitting\n",
            "0025/0030: virat_VIRAT_S_000102_exiting_vehicle_97.mp4 is predicted to class sitting, original class sitting\n",
            "0026/0030: virat_VIRAT_S_040005_08_001225_001276_entering_vehicle_6.mp4 is predicted to class sitting, original class sitting\n",
            "0027/0030: virat_VIRAT_S_040005_06_000886_001016_exiting_vehicle_23.mp4 is predicted to class sitting, original class sitting\n",
            "0028/0030: virat_VIRAT_S_040005_07_001026_001223_entering_vehicle_41.mp4 is predicted to class sitting, original class sitting\n",
            "0029/0030: virat_VIRAT_S_040103_03_000284_000425_exiting_vehicle_40.mp4 is predicted to class sitting, original class sitting\n",
            "Accuracy of class walking is 50.00\n",
            "Accuracy of class running is 70.00\n",
            "Accuracy of class sitting is 90.00\n",
            "Total test accuracy is 70.00\n",
            "Total inference time is 0.39 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SlowFast Training"
      ],
      "metadata": {
        "id": "Oy-POB0u38qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VideoClsCustom(root=os.path.expanduser('/content/drive/MyDrive/new'),\n",
        "                               setting=os.path.expanduser('/content/train.txt'),\n",
        "                               train=True,\n",
        "                               new_length=64,\n",
        "                               slowfast=True,\n",
        "                               slow_temporal_stride=16,\n",
        "                               fast_temporal_stride=2,\n",
        "                               transform=transform_train,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True)\n",
        "print('Load %d training samples.' % len(train_dataset))\n",
        "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RptlbNRU3-ws",
        "outputId": "e7b7e8fe-5c9d-4778-bafc-b9b96ae551d7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load 60 training samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net_slowfast = get_model(name='slowfast_4x16_resnet50_custom', nclass=3)\n",
        "net_slowfast.collect_params().reset_ctx(ctx)\n",
        "print(net_slowfast)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HK5d8Lo4q0g",
        "outputId": "96946fc5-56af-4ad7-9fee-a056a981e9f0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SlowFast(\n",
            "  (fast_conv1): Conv3D(3 -> 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
            "  (fast_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "  (fast_relu): Activation(relu)\n",
            "  (fast_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  (fast_res2): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(8 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)\n",
            "      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (fast_res3): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(32 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(32 -> 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (fast_res4): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(64 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(64 -> 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
            "      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (fast_res5): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(128 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(128 -> 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (lateral_p1): HybridSequential(\n",
            "    (0): Conv3D(8 -> 16, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (lateral_res2): HybridSequential(\n",
            "    (0): Conv3D(32 -> 64, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (lateral_res3): HybridSequential(\n",
            "    (0): Conv3D(64 -> 128, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (lateral_res4): HybridSequential(\n",
            "    (0): Conv3D(128 -> 256, kernel_size=(5, 1, 1), stride=(8, 1, 1), padding=(2, 0, 0), bias=False)\n",
            "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "    (2): Activation(relu)\n",
            "  )\n",
            "  (slow_conv1): Conv3D(3 -> 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
            "  (slow_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "  (slow_relu): Activation(relu)\n",
            "  (slow_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
            "  (slow_res2): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(80 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(80 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
            "      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (slow_res3): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(320 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(320 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
            "      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (slow_res4): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(640 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(640 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
            "      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (slow_res5): HybridSequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv3D(1280 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      (relu): Activation(relu)\n",
            "      (downsample): HybridSequential(\n",
            "        (0): Conv3D(1280 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
            "        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
            "      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
            "      (relu): Activation(relu)\n",
            "    )\n",
            "  )\n",
            "  (avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
            "  (dp): Dropout(p = 0.5, axes=())\n",
            "  (fc): Dense(2304 -> 3, linear)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = gluon.Trainer(net_slowfast.collect_params(), optimizer, optimizer_params)"
      ],
      "metadata": {
        "id": "UDoF_2S-4_mz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 9\n",
        "lr_decay_count = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    tic = time.time()\n",
        "    train_metric.reset()\n",
        "    train_loss = 0\n",
        "\n",
        "    # Learning rate decay\n",
        "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
        "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
        "        lr_decay_count += 1\n",
        "\n",
        "    # Loop through each batch of training data\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        # AutoGrad\n",
        "        with ag.record():\n",
        "            output = []\n",
        "            for _, X in enumerate(data):\n",
        "                X = X.reshape((-1,) + X.shape[2:])\n",
        "                pred = net_slowfast(X)\n",
        "                output.append(pred)\n",
        "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
        "\n",
        "        # Backpropagation\n",
        "        for l in loss:\n",
        "            l.backward()\n",
        "\n",
        "        # Optimize\n",
        "        trainer.step(batch_size)\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
        "        train_metric.update(label, output)\n",
        "\n",
        "        if i == 100:\n",
        "            break\n",
        "\n",
        "    name, acc = train_metric.get()\n",
        "\n",
        "    # Update history and print metrics\n",
        "    train_history.update([acc])\n",
        "    print('[Epoch %d] train=%f loss=%f time: %f' %\n",
        "        (epoch, acc, train_loss / (i+1), time.time()-tic))\n",
        "\n",
        "# We can plot the metric scores with:\n",
        "train_history.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "SOFYxn0Y5SFZ",
        "outputId": "39d33e80-bf77-4e2a-a6fe-e6785f9818e9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0] train=0.300000 loss=1.121230 time: 25.362383\n",
            "[Epoch 1] train=0.550000 loss=1.030431 time: 20.607928\n",
            "[Epoch 2] train=0.533333 loss=0.937650 time: 20.581192\n",
            "[Epoch 3] train=0.733333 loss=0.849303 time: 20.550207\n",
            "[Epoch 4] train=0.766667 loss=0.707029 time: 20.654498\n",
            "[Epoch 5] train=0.850000 loss=0.634124 time: 20.521149\n",
            "[Epoch 6] train=0.816667 loss=0.574124 time: 20.273251\n",
            "[Epoch 7] train=0.900000 loss=0.449278 time: 20.631335\n",
            "[Epoch 8] train=0.866667 loss=0.419384 time: 20.208493\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c+djZAFskIge2Qn7IEg7gqyVEFFUcCtdXls1dqfrT5oXar2sVpb+1QfbQWktgJu4IIKiFgXVBI2Awl7yB4SkhDIvs/9+2MmaQwJmZBZMmeu9+vFi1lOZi4Ok29O7nOf+1Jaa4QQQhiPh7MLEEIIYR8S8EIIYVAS8EIIYVAS8EIIYVAS8EIIYVAS8EIIYVDdBrxSapVSqkQpldHF80op9ZJSKlMptU8pNdn2ZQohhOgpa47g3wDmnOX5ucBwy5+7gb/1viwhhBC91W3Aa62/AcrPsskC4F/aLAUIUkoNsVWBQgghzo2XDV4jEshvd7/A8lhRxw2VUndjPsrH399/yqhRo2zw9kII4T52795dprUOt2ZbWwS81bTWy4HlAElJSXrXrl2OfHshhHB5Sqlca7e1xSyaQiC63f0oy2NCCCGcyBYBvwG41TKbZjpQobU+Y3hGCCGEY3U7RKOUegu4FAhTShUATwLeAFrrvwMbgXlAJlAL/NRexQohhLBetwGvtV7czfMauNdmFQkh+oympiYKCgqor693dilux9fXl6ioKLy9vc/5NRx6klUI4VoKCgoIDAwkLi4OpZSzy3EbWmtOnjxJQUEB8fHx5/w6slSBEKJL9fX1hIaGSrg7mFKK0NDQXv/mJAEvhDgrCXfnsMV+l4AXQgiDkoAXQvRZp0+f5tVXX+3x182bN4/Tp0+fdZsnnniCrVu3nmtpLkECXgjRZ3UV8M3NzWf9uo0bNxIUFHTWbZ5++mlmzpzZq/r6Ogl4IUSftWzZMo4dO8bEiROZOnUqF110EfPnz2fMmDEAXHPNNUyZMoWxY8eyfPnytq+Li4ujrKyMnJwcRo8ezV133cXYsWO58sorqaurA+D2229n3bp1bds/+eSTTJ48mXHjxnHo0CEASktLmTVrFmPHjuXOO+8kNjaWsrKyM+rcsWMH559/PpMmTWLGjBkcPnwYgJaWFn7zm9+QmJjI+PHjefnllwHYuXMnM2bMYMKECUybNo2qqiq77D+ZJimEsMpTH+/nwPFKm77mmKEDePLqsV0+/9xzz5GRkUFaWhpfffUVP/nJT8jIyGibOrhq1SpCQkKoq6tj6tSpLFy4kNDQ0B+9xtGjR3nrrbdYsWIFixYtYv369dx8881nvFdYWBh79uzh1Vdf5U9/+hMrV67kqaee4vLLL+eRRx5h8+bNvP76653WOWrUKLZt24aXlxdbt27l0UcfZf369SxfvpycnBzS0tLw8vKivLycxsZGbrzxRt555x2mTp1KZWUl/fv378Ve7JoEvBDCZUybNu1H88JfeuklPvjgAwDy8/M5evToGQEfHx/PxIkTAZgyZQo5OTmdvvZ1113Xts37778PwLffftv2+nPmzCE4OLjTr62oqOC2227j6NGjKKVoamoCYOvWrdxzzz14eZmjNiQkhPT0dIYMGcLUqVMBGDBgQI/3g7Uk4IUQVjnbkbaj+Pv7t93+6quv2Lp1K9u3b8fPz49LL72003nj/fr1a7vt6enZNkTT1Xaenp7djvG/8sorrFixAjCP9z/++ONcdtllfPDBB+Tk5HDppZf29J9mFzIGL4ToswIDA7scn66oqCA4OBg/Pz8OHTpESkqKzd//ggsu4N133wVgy5YtnDp1CoB7772XtLQ00tLSGDp0KBUVFURGRgLwxhtvtH39rFmzeO2119p+YJSXlzNy5EiKiorYuXMnAFVVVd3+QDlXEvBCiD4rNDSUCy64gMTERB566KEfPTdnzhyam5sZPXo0y5YtY/r06TZ//yeffJItW7aQmJjIe++9R0REBIGBgWds9/DDD/PII48wadKkH4X1nXfeSUxMDOPHj2fChAmsXbsWHx8f3nnnHe6//34mTJjArFmz7LbWjzKvFeZ40vBDiL7v4MGDjB492tllOE1DQwOenp54eXmxfft2fv7zn5OWluaw9+9s/yuldmutk6z5ehmDF0KILuTl5bFo0SJMJhM+Pj5t4+6uQgJeCCG6MHz4cH744Qdnl3HOZAxeCHFWzhrG7UtMWlNcUc/J6gZaTI7ZH7bY73IEL4Tokq+vLydPnnTrJYNNWpNfXktFnXlue1FFPUF+3oT6+9Dfxz4R2roevK+vb69eRwJeCNGlqKgoCgoKKC0tdXYpTqG1pry2ibrGFoL8vPHx9KCyoZnipha0Bh8vD/x9PPHz8bT5D8DWjk69IQEvhOiSt7d3rzoKubLmFhMPvJPGp/uKeOwno5k1MaHtuYraJtbvKWDtt3lkllQT6OvFwslRLEmOYcTgM6dROotMkxRCiA6aW0w8+O5eNuw9zqPzRnH3xed1up3Wmh3Z5azdkcem9GIaW0xMjQtmaXIscxIj8PX2tHltPZkmKQEvhBDttJg0v343jQ/TjvPfc0bx80s7D/eOymsaWbc7n7WpeeScrCXYz5vrp0SxeFoMCeEBNqtPAl4IIc5Bi0nz0Lq9vL+nkIdmj+Tey4b1+DVMJs33x06ydkcuW/afoNmkmXFeKEuTY5k1ZjA+Xr2bvCgBL4QQPWQyaR5ev491uwt4cNYIfnnF8F6/ZklVPe/tKmBtah6Fp+sIC/BhUVI0S5JjiAr2O6fX7EnAyzx4IYTbM5k0j7yfzrrdBTxwxXCbhDvAoEBf7r1sGN88fBn/uH0qE6OD+fvXx/j6iGNmJcksGiGEWzOZNL/9MIN3duVz/+XD+NVM24R7e54eistGDeKyUYM4frqOgf29bf4enZGAF0K4La01T2zI4K0defzi0vN4cNYIu1/QNTTIPt2bOiNDNMJuiivquXftHt74LpvmFpOzy+HLwyXcu2YPZdUNzi5FdKPFpPn9Jwd45P197Cs4bZf30Frz5Ib9rE7J478uSeCh2SMNd7WuHMELu9idW849q/dQXtPIp/uKeHdXAb+/NpHJMZ23PLOn46frePrjA2zeXwzAzDGDuHZS764QFPbTYtI8vG4f6/cU4OPlwVs78kmMHMDS5FjmTxiKf7/ex5bWmqc+PsC/tudy10XxLJszynDhDnIEL+zg7R153LQ8BT8fTzY9cBGvLp1MeU0j1736PcvW7+NUTaND6mhsNvG3r45xxZ+/5qsjJTw4awQeCrJLaxzy/qLnTCbNsvXmcP/VzOHsemwmzywYS3OL+SRo8rNf8NiH6b1q/q215vefHuSN73P42QXxPDpvtCHDHWSapLChphYTz3xiPiq6aHgYLy+eRJCfDwDVDc289MVRXv82m0BfL5bNGcWipGg8POzzjbX92Eke/yiDzJJqZo0ZzBNXjSE6xI9LXviSxMiBvLJksl3eV5w7k0nz6AfpvL0zn19ePowHrxzZ9pzWmj15p1mTmssn+4pobDYxKSaIpcmxXDV+iNVXjGqt+cOmQyz/JovbZ8Tx5NVjXC7cZR68cLiT1Q38Ys0eUrPLufviBB6ePRIvzzN/QTxcXMXjH2awI6ecSTFBPLMgkcTIgTaro6Sqnmc/PciHaceJCu7PU/PHcsXowW3P3/6PHZRUNrDxgYts9p6i90wmzWMfZbA2NY97LzuP31zZ9Xj46dpG1u8pZE1qLlmlNQzw9WLhlCiWJscwbFDX68BorXl+82H+/vUxbj0/lqfmj3W5cAcJeOFgGYUV/NebuymrbuD5heO5ZlLkWbfXWvP+nkL+sOkg5TWN3Hp+HA9eOYIBvuc+day5xcTqlFz+vOUIDc0m7rkkgV9cNuyMI7unPz7AWzvyOPD0bJf85jYirTWPf5TB6pQ87rnkPP57jnUnO7XWpGaXsyY1j80ZRTS1aKbFh7A0OYY5iRH08/L80bZ/2nKYV748xtLkGH5/TaLL/v9Lyz7hMBv2HufhdXsJ9vNh3T0zGBfV/dG4UoqFU6KYOWYwf95ymH9uz+ETy4p9CyYO7fE33p68Uzz2QQYHiiq5aHgYTy9IJD7Mv9Nt48P9qWtqobiyniEDHTddTXSu9WTn6pQ87r44wepwB/PnaHpCKNMTQimrHsO63eYrRh94O40Qfx9usKwDExfmz18+P8IrXx5j8bRonlnguuHeU3IEL85Ji0nzwmfmX3enxgXz6tIphAf2O6fXSi+o4LEP09lbUMH0hBCeWZDIcCuWXD1V08jzmw/x9s58Igb48vhVY5g3LuKs37zfZZaxdGUqa+9MZsawsHOqV9iG1ppnPjnIqu+yuePCeB77Se9PdppMmu+OlbEmJY/PD56gxaQZM2QAB4oquTEpmj9cN85u530cRY7ghV1V1DXxwNs/8NXhUpYmx/Dk1WN7tYDSuKiBvP+LC3h7Zx5/3HyYuX/dxh0XxfPLy4d3OiXOZNK8uyuf5zcforK+mbsvTuCXVwwnwIrpcwnh5iP7rLIaCXgn0lrz7EZzuP/0gjibhDuAh4fiouHhXDQ8nBOV9by7M5/3dheweFoM/3NNosuHe09ZFfBKqTnAXwFPYKXW+rkOz8cA/wSCLNss01pvtHGtog/ILKnirn/tJr+8lv+5NpGlybE2eV1PD2VeQ3tsBM9tOsRrX2fxcdpxnrh6DLPH/ueofP/xCh77MIMf8k4zLS6EZ65JZGSE9Q0WBgf60t/bkyyZKuk0Wmue23yIFduyue38WJ64yj4zWQYP8OX+K4Zzv43WlXFF3Qa8UsoTeAWYBRQAO5VSG7TWB9pt9hjwrtb6b0qpMcBGIM4O9Qon2nrgBL96Jw1fbw/euns6U+NCbP4eoQH9eOGGCdw4NZrHPszgntV7uGREOA/NHsm63QX8a3sOIf4+/PmGCVw3ObLHweDhoYgL8ye7rNrmtYvuaW0e2nvt6yxunh7D71x0JoursOYIfhqQqbXOAlBKvQ0sANoHvAYGWG4PBI7bskjhXFpr/u/fmby49QiJQwfy2i1T7L6eRlJcCJ/cfyH/3J7LXz4/wlUvf4tScMv0WH595cheLdaUEO7P/sIKG1YrrKG15sXPj/DqV8dYPC2Gp+e7z8lOZ7Em4COB/Hb3C4DkDtv8DtiilLof8AdmdvZCSqm7gbsBYmJielqrcIKahmZ+895eNmUUc+2kSP5w3Ti7tCHrjJenB3dcGM9V44fw5vZcrhw7mPFRQb1+3YQwfzZnFNPYbOp18wVhvf/depSX/53JTVOj3XI83Bls9eleDLyhtY4C5gFvKqXOeG2t9XKtdZLWOik8PNxGby3sJb+8loV/+57P9hfz23mjeXHRBIeFe3uDB/jym9kjbRLuAPFh/rSYNHnltTZ5PdG9l744yl+/OMoNU6J49lrXn8niKqw5gi8Eotvdj7I81t4dwBwArfV2pZQvEAaU2KJI4Vhaa74+Usqv3knDZNK88dNpXDzCOD+QW/tjZpfVMGyQ7Xplis698mUmL35+hOsmR/LcwvES7g5kTcDvBIYrpeIxB/tNwJIO2+QBVwBvKKVGA76AY1qWCJupbmjmo7RC1qTkcaCokuGDAlhxaxJxXVw05KriQy1TJUurgcFn31j0yt++OsYLnx3m2kmRvHD9BDwl3B2q24DXWjcrpe4DPsM8BXKV1nq/UuppYJfWegPwa2CFUur/YT7hert21hVUoscyCitYuyOPj34opKaxhdFDBvD7axK5bnIkfj7Gu1RioJ83of4+ZJfJVEl7Wv7NMZ7ffIj5E4bypxsk3J3Bqu9ey5z2jR0ee6Ld7QPABbYtTdhTXWMLH+87zprUPPbmn6aflwdXTxjK0uQYJkYHGX52Q0K4P1kS8HazclsWz248xE/GD+HFRRLuzmK8wzNxVkdOVLE2NY/1ewqoqm9m2KAAnrx6DNdNimKgn2P6RPYF8WH+/PuQjCLaWlFFHf/4Lofl32QxNzGC/71xYqerigrHkIB3A/VNLWzOKGZNai47c07h4+nB3HERLE2OZWpcsOGP1jsTHxZAWXUBlfVNvVrFUpjXJfrmaClrU/P44uAJTBqumxTJ89ePx1vC3akk4A0sq7Sat3bksW53Aadqm4gL9ePReaO4fko0If4+zi7PqVpXm8wpq7HZ9Et3U1rVwLu78nlrRx4Fp+oI9ffh7ovPY/G0aGJDjXVi3lVJwBtMY7OJLQeKWZuax/fHTuLlobhy7GCWJsdyfkKoTFGzOK910bFSCfieMJk027NOsjY1j8/2F9Ns0pyfEMp/zxnF7LERcuFYHyMBbyAlVfUsXZHK0ZJqIoP689DskdyQFMWgQF9nl9bnxIT6oRRyotVK5TWNrN9dwNodeWSX1TCwvze3zYhj8bQYuZagD5OAN4jSqgaWrEjl+Ok6/n7zZGaNiZCZC2fRz8uTqOD+MlXyLLTW7Mo9xZqUXDamF9PYYmJKbDD3Xz6MeeOs74MqnEcC3gDKqhtYujKFwlN1/OOnU5meEOrsklxCQliA5WIn0V5FXRMf7ClgTWoeR0uqCeznxU3TolmSHMOoiAHdv4DoMyTgXVx5TSM3r0wlr7yWVbdLuPdEfJg/O3PK0Vq75UyijgpP1/G/nx/h433HqW8yMT5qIM8vHMfVE4Ya8oI3dyD/ay7sVE0jS1akkF1Ww6rbpzLjPOlQ1BMJ4f7UNrZQUtXA4AFynuKh9/ayJ+8U106KZMm0WKv664q+TQLeRZ2ubWTpylSyympYeWsSF0j7uR5LCDOfHDxWWu32AZ9ZUs33x07y0OyR3HvZMGeXI2xE5jS5oIraJm5+PZXMkmqW3zLFUCs9OlK8ZaqknGiFNam5eHsqbpwa3f3GwmVIwLuYirombl2VypHial67ZQqXjhzk7JJc1pABvvh6e5Dt5v1ZaxubWbe7gLmJQwgL6OfscoQNScC7kKr6Jm5btYMDRZX87ebJXDZKwr03PDwUcaGy6NjHe49TVd/MzdNt00Bd9B0S8C6iuqGZ21btIKOwgleWTOaK0bKOuS0khPu79RCN1po3U3IZOTiQqXHBzi5H2JgEfC81NLdQVd9k1/eobmjm9lU72FdQwf8tmcyVYyPs+n7uJD7Mn7zyWppaTM4uxSn2FlSQUVjJzdNjZKqoAUnA99Kv393L5Gc+5/63fiAl6yS27nNS09DMz/6xkx/yT/PS4knMSZRwt6WEsAC37s+6OiUXPx9PrpkU6exShB3INMleyC6r4dP0IsZHBfH14RI+3nuc88L9WZIcy8LJkQT59W7FxtrGZn72xk525Zbz15smMW/cEBtVLlq1zaQpreG8cPdaU+V0bSMf7z3O9VOiCJQlkw1JAr4XVn2bjbeHBytunUJgP28+TS9iTWouz3xygD9uNnezWZocy+SYnndIqmts4Y43drEzp5y/3DiRqycMtdO/wr0lhLnvVMl1uwtoaDbJyVUDk4A/R6dqGnlvdz4LJg5tW63x+ilRXD8ligPHK1m7I5cP9hTy/p5CRkUEsjQ5hmsmRVp1pFTf1MJd/9pFSvZJXlw0gQUT5ddnewny8yHE38ftZtKYTJo1qXkkxQYzeoisL2NUMgZ/jtak5lLfZOLOixLOeG7M0AH8/ppxpP52Js9eOw5PD8XjH+0n+dkvWLZ+H+kFFV2+bmu4f3esjD9dP4FrJ0XZ858hMJ9odbdFx747VkZ2WY0cvRucHMGfg4bmFv65PZeLR4QzMiKwy+0C+nmxJDmGxdOi2VdQwdrUPD5MK+TtnfmMixzI0uQY5k/8z0JODc0t/Nebu/k2s4znF45n4RQJd0eID/PnmyPu1Z91dUouIf4+zB0nJ+2NTI7gz8FHaccprWrgrovirdpeKcWE6CCev348qY/O5Kn5Y2lsNrHs/XSS/+cLHv8wg/SCCn6+eg9fHynluevGsShJLhl3lIRwf0qqGqhuaHZ2KQ5RVFHH1oMlLEqKpp+XrOluZHIE30Naa17fls2oiEAuPIcFvlo74dx6fiy7c0+xNjWPd3bl82ZKLgDPXjuOG6fG2LpscRZtJ1pLa9xiBcW3duRj0pqlyfI5MzoJ+B765mgZh09U8acbJvTqwhClFElxISTFhfD4VWP44IdCBg3ox1XjZbaMo8VbVpXMKqs2fMA3tZh4e0cel4wIJzrEz9nlCDuTgO+hlduyGBTYj/k2nLYY7O/Dzy60brhH2F6spT+rO0yV/PzACUqqGviDnFx1CzIG3wMHiyrZdrSM22bESfd4A/H19iQyqD9ZbrCq5OqUXCKD+ssqpG5CUqoHVm7Lpr+3p4xdGlB8mPEXHWtt6rEkOUYasrsJCXgrnaisZ8PeQhYlRfV6CQLR9yRYAt7Wawn1JdLUw/1IwFvpX9tzaDZpGSs3qITwAKobmimtanB2KXbR2tRjjjT1cCsS8FaobWxmdUoes8dEEBvq7+xyhB3EW6ZKGnXJgtamHrfIyVW3IgFvhXW7C6ioa+Kui+Xo3ajiDb7o2OqUPEYMDpCmHm5GAr4bLSbN699mMykmiCmxIc4uR9hJZFB/fLw8DLkmzd7806QXVnDL9Fhp6uFmJOC78fmBE+SerOWuThYVE8bh4aGIDzXmTJo3pamH25KA78bKbVlEh/RntrTJM7z4MOM14G5t6mHtUtXCWKwKeKXUHKXUYaVUplJqWRfbLFJKHVBK7VdKrbVtmc7xQ94pduWe4mcXxMu8YTeQEO5P3klj9Wdta+qRLCdX3VG3SxUopTyBV4BZQAGwUym1QWt9oN02w4FHgAu01qeUUoa4TG7ltmwG+HrJyo5uIj7Mn2aTpuBUXdtJV1fW2tRjSmwwY4ZKUw93ZM0R/DQgU2udpbVuBN4GFnTY5i7gFa31KQCtdYlty3S8/PJaNmUUsSQ5Fv9+smSPO0ho7c9aZowTrd8fO2lp6iFXXrsrawI+Eshvd7/A8lh7I4ARSqnvlFIpSqk5nb2QUupupdQupdSu0tK+3WBh1XfZeCjFbTPkV1t3kdC6qqRB1qR5MyXH3NQjUZq1uytbnWT1AoYDlwKLgRVKqaCOG2mtl2utk7TWSeHh4TZ6a9urqGvi3Z35XD1hKEMG9nd2OcJBgv19CPLzNsSJ1tamHjckReHrLU093JU1AV8ItB+EjrI81l4BsEFr3aS1zgaOYA58l/TWjjxqGlu408qOTcI44sP8yTbAEXxbU49p8huoO7Mm4HcCw5VS8UopH+AmYEOHbT7EfPSOUioM85BNlg3rdJjGZhNvfJfDjPNCGTvU2M0fxJkSwgLIcvEx+PZNPWJCpamHO+s24LXWzcB9wGfAQeBdrfV+pdTTSqn5ls0+A04qpQ4AXwIPaa1P2qtoe/o0/TjFlfVyYZObSgj350RlAzUu3J91q6Wph0yNFFZND9FabwQ2dnjsiXa3NfCg5Y/L0lqz4ptshg0K4JIRffccgbCf9mvSJEa65m9wb1qaelw2yhCzlUUvyJWs7Ww/dpIDRZXceWE8HnJhk1tqnSrpqidapamHaE8Cvp0V27IIC/CRNTvcWJxlOWhXPdHa2tRDLs4TIAHfJrOkii8Pl3LL9DiZVubGWvuzuuLFTnWNLay3NPUID5SmHkICvs3Kbdn08/KQq/4ECeGuuejYx3uPU1nfzM3SM1hYSMADpVUNvP9DIQunRBEq7czcXutceHv3Zz1RWc/LXxxlU3oRBadqe/1+b6bkMmJwANPipW+BMJNFVjB/YzQ2m7hD+q0KzAFf1dBMWXWjXYc6Xvs6i1XfZbfdD/H3YVzkQPOfqIGMjxpIxABfq5p0tDb1eHrBWGnqIdq4fcDXN7WwOiWXmaMHcV54gLPLEX1AQnjrmjTVdgt4k0mzKaOIS0eG8/9mjmBfYQXpBafZV1DBt5lltJjMR/NhAf0YHzWwLfjHRw1k0ADfM16vtanHtTJBQLTj9gG/fk8B5TWN3CkXNgmLhHZz4ZMTQu3yHmkFpymqqOeh2SOZEB3EhOggwHxhUn1TCweKKkkvqGBfQQXphaf56nAJlsxn8IB+jIsMagv8mFA/Pt57nIVToqSph/gRtw54k0nz+rZsxkUOJFnGLYXF0KD++Hh62LV936b0Irw9FVeMHnzGc77enkyOCWZyzH8aZNc2NnPgeKUl8CvYV3CaLw6doP2wvVy5Kjpy64D/96ESsspq+OtNE2XcUrTx9FDEhvpxzE5z4bXWbEwv5sJhYQzsb90Rt5+PF0lxISTF/edApKq+if3HK8korMDb00OaeogzuHXAr9iWxdCBvswbJ+tlix9LCPcns8Q+c+H3FVRQeLqOX83s3YKrgb7eTE8IZbqdhpGE63PbaZLpBRWkZpfz0wvi8fZ0290guhAfFkBeeS3NdujPujGjCC8PxawxZw7PCGFLbpts//gum4B+Xtw4TS7pFmdKCPOnqcXcn9WWtNZsSi9mxrAwgvx8bPraQnTklgFfXtPIJ/uKuG5yJANk1oHoxH/6s9p2HH7/8UryymuZlxhh09cVojNuGfDv7cqnscXEzdNl1oHoXOuywbZesmBjehGeHoorx0rAC/tzu4A3mTRrUvOYFh/CiMGBzi5H9FEh/j4M8PUiq9R2J1rNs2eKOD8hlBB/GZ4R9ud2Af/N0VLyymvl6F2clVKKhPAAmw7RHCquIudkLXPHydG7cAy3C/jVKbmEBfgwR35FFt1ICPO3acBvTC/CQ8Fs+ewJB3GrgC88Xce/D5Vw49RofLzc6p8uzkF8mD9FFfXUNva+P6vWmk/Ti0iODyVMViwVDuJWKfdWah4aWDxN1ssW3WtddMwWR/FHS6rJKq1hngzPCAdym4BvbDbx9s48rhg1iKhgP2eXI1xA+wbcvfXpviKUgtkyPVI4kNsE/Gf7iymrbmSpnFwVVooLMx8IZNlgTZpNGUVMjQthUOCZS/0KYS9uE/BvpuQSHdKfS4aHO7sU4SL8fLwYOtC310fwmSVVHDlRLRc3CYdzi4A/cqKKHdnlLE2OxcNDVo0U1ou3QX/WjenFAMyVRe2Eg7lFwK9JycXH04MbpkQ5uxThYuLD/Mkqre5Vv9SN6UUkxQYzuJNOTELYk+EDvqahmfV7CvnJ+CHSUFv0WAmaVfQAAA2TSURBVEJYAFX1zZysaTynr88qreZQcZUcvQunMHzAf5R2nOqGZm6eLlMjRc/F93LRsU0ZluEZGX8XTmDogNda82ZKLqMiAn/U/kwIa7X1Zz3HmTQb04uYFBPE0KD+tixLCKsYOuD35J3mYFElt5wfKy35xDmJCvbD21NxrKzni47lnqxh//FK5iXK8IxwDkMH/OqUXAL6eXHNxEhnlyJclLk/q/85HcG3Dc/I1avCSQwb8OU1jXxqaerh38+tW8+KXoo/x0XHNqYXMSFqoFw5LZzGsAEvTT2ErSSE+ZN7spYWk/VTJfPLa9lXUCGzZ4RTGTLg25p6xElTD9F7CeH+NLaYKOxBf9bNluEZGX8XzmTIgG9r6nG+HL2L3osPM68qmdWDE62fpheRGDmAmFAZnhHOY8iAl6Yewpba+rNaeaK18HQdafmnmStH78LJrAp4pdQcpdRhpVSmUmrZWbZbqJTSSqkk25XYM61NPRYlSVMPYRthAT4E+npZfaK1bXhGxt+Fk3WbgEopT+AVYC4wBlislBrTyXaBwANAqq2L7InWph5LkuXKVWEbSqkete/blF7E6CED2o78hXAWaw5xpwGZWussrXUj8DawoJPtngGeB+ptWF+PtDb1uHykNPUQttW66Fh3iivq2ZV7SpYGFn2CNQEfCeS3u19geayNUmoyEK21/vRsL6SUulsptUsptau0tLTHxXantamHnFwVtpYQHsDxinrqGlvOut3mjCJAlgYWfUOvB6mVUh7Ai8Cvu9tWa71ca52ktU4KD7d94w1p6iHspXW4Jefk2YdpNmYUM3JwIMMGBTiiLCHOypqALwSi292PsjzWKhBIBL5SSuUA04ENjj7R2trUY8k0aeohbM+amTQllfXszCmXpQlEn2FNwO8Ehiul4pVSPsBNwIbWJ7XWFVrrMK11nNY6DkgB5mutd9ml4i60NvVYlCRNPYTt/acBd9fj8J/tL0ZrmT0j+o5uA15r3QzcB3wGHATe1VrvV0o9rZSab+8CrdHa1GPeuAhp6iHswr+fFxEDfM/avm9jejHDBgXI1dOiz7BqFS6t9UZgY4fHnuhi20t7X1bPtDb1uEVOrgo7Ms+k6Tzgy6obSM0+yX2XDXNwVUJ0zeWvBJKmHsJREsK77s/62f5iTFpmz4i+xeUDvrWpx83TpamHsK/4MH8q65s5Vdt0xnOb0otJCPNnVIQMz4i+w+UDfk1rU49J0tRD2FdCeOtMmh+faC2vaWR71knmjouQgwzRp7h0wJfXNPLJviKunRRJgDT1EHaW0Laq5I/H4bfsL6bFpGVxMdHnuHTAS1MP4UhRwf3x8lBnrEmzMaOY2FA/xg4d4KTKhOicywZ8+6YeI2XcUziAl6cHMaF+PxqiOV3byPeZZcxNHCLDM6LPcdmAb23qsXS6rBopHCchLOBHR/BbDpyg2aSZJ1evij7IZQN+dUqeuamHrNonHCgh3J+cdv1ZN6UXERXcn3GRA51cmRBncsmANzf1OMGipGj6eXk6uxzhRuLD/GlsNnH8dB0VdU18m1nGvHEyPCP6JpeceiJNPYSzJLQuOlZWQ1lVA00tmrnyW6Too1wu4KWph3CmeMtc+OzSar7NLGPoQF8mRgc5uSohOudyQzRtTT1kaqRwgvCAfgT082JfQQXfHCljrgzPiD7M5Y7gvT09uGREOBePkKYewvGUUsSH+fPxvuM0tcjsGdG3uVzAz0mMkJkzwqkSwv1JL6wgYoAvk6JlgTvRd7ncEI0Qztba/GNOYoR0DxN9mgS8ED3UumLkVeNl7RnRt7ncEI0QznblmAg23HcB46Nk9ozo2+QIXoge8vBQEu7CJUjACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQUnACyGEQVkV8EqpOUqpw0qpTKXUsk6ef1ApdUAptU8p9YVSKtb2pQohhOiJbgNeKeUJvALMBcYAi5VSYzps9gOQpLUeD6wD/mjrQoUQQvSMNUfw04BMrXWW1roReBtY0H4DrfWXWutay90UIMq2ZQohhOgpawI+Eshvd7/A8lhX7gA2dfaEUupupdQupdSu0tJS66sUQgjRYzY9yaqUuhlIAl7o7Hmt9XKtdZLWOik8PNyWby2EEKIDLyu2KQSi292Psjz2I0qpmcBvgUu01g22KU8IIcS5suYIficwXCkVr5TyAW4CNrTfQCk1CXgNmK+1LrF9mUIIIXqq24DXWjcD9wGfAQeBd7XW+5VSTyul5ls2ewEIAN5TSqUppTZ08XJCCCEcxJohGrTWG4GNHR57ot3tmTauSwghRC/JlaxCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQEvBCCGFQVgW8UmqOUuqwUipTKbWsk+f7KaXesTyfqpSKs3WhQggheqbbgFdKeQKvAHOBMcBipdSYDpvdAZzSWg8D/gI8b+tChRBC9Iw1R/DTgEytdZbWuhF4G1jQYZsFwD8tt9cBVyillO3KFEII0VNeVmwTCeS3u18AJHe1jda6WSlVAYQCZe03UkrdDdxtuVutlDp8LkUDYR1f2wVIzY7hajW7Wr0gNTtKVzXHWvsC1gS8zWitlwPLe/s6SqldWuskG5TkMFKzY7haza5WL0jNjmKLmq0ZoikEotvdj7I81uk2SikvYCBwsjeFCSGE6B1rAn4nMFwpFa+U8gFuAjZ02GYDcJvl9vXAv7XW2nZlCiGE6Kluh2gsY+r3AZ8BnsAqrfV+pdTTwC6t9QbgdeBNpVQmUI75h4A99XqYxwmkZsdwtZpdrV6Qmh2l98PZcqAthBDGJFeyCiGEQUnACyGEQfXpgHe1JRKUUtFKqS+VUgeUUvuVUg90ss2lSqkKpVSa5c8Tzqi1Q005Sql0Sz27OnleKaVesuznfUqpyc6o01LLyHb7Lk0pVamU+lWHbZy+j5VSq5RSJUqpjHaPhSilPldKHbX8HdzF195m2eaoUuq2zrZxYM0vKKUOWf7fP1BKBXXxtWf9DDm45t8ppQrb/f/P6+Jrz5ovDq75nXb15iil0rr42p7tZ611n/yD+YTuMSAB8AH2AmM6bPML4O+W2zcB7zi55iHAZMvtQOBIJzVfCnzi7P3boaYcIOwsz88DNgEKmA6kOrvmdp+RYiC2r+1j4GJgMpDR7rE/Assst5cBz3fydSFAluXvYMvtYCfWfCXgZbn9fGc1W/MZcnDNvwN+Y8Vn56z54siaOzz/Z+AJW+znvnwE73JLJGiti7TWeyy3q4CDmK/ydXULgH9psxQgSCk1xNlFAVcAx7TWuc4upCOt9TeYZ5S11/7z+k/gmk6+dDbwuda6XGt9CvgcmGO3QtvprGat9RatdbPlbgrm62D6jC72szWsyRe7OFvNlvxaBLxli/fqywHf2RIJHcPyR0skAK1LJDidZbhoEpDaydPnK6X2KqU2KaXGOrSwzmlgi1Jqt2U5iY6s+b9whpvo+huhr+1jgMFa6yLL7WJgcCfb9NV9DfAzzL/Jdaa7z5Cj3WcZVlrVxVBYX93PFwEntNZHu3i+R/u5Lwe8y1JKBQDrgV9prSs7PL0H85DCBOBl4ENH19eJC7XWkzGvGHqvUupiZxfUHctFd/OB9zp5ui/u4x/R5t+3XWaOslLqt0AzsKaLTfrSZ+hvwHnARKAI85CHq1jM2Y/ee7Sf+3LAu+QSCUopb8zhvkZr/X7H57XWlVrrasvtjYC3UirMwWV2rKnQ8ncJ8AHmX1/bs+b/wtHmAnu01ic6PtEX97HFidahLcvfJZ1s0+f2tVLqduAqYKnlB9MZrPgMOYzW+oTWukVrbQJWdFFLX9zPXsB1wDtdbdPT/dyXA97llkiwjJ+9DhzUWr/YxTYRrecJlFLTMP8fOO2HklLKXykV2Hob80m1jA6bbQButcymmQ5UtBtqcJYuj3T62j5up/3n9Tbgo062+Qy4UikVbBlauNLymFMopeYADwPztda1XWxjzWfIYTqcH7q2i1qsyRdHmwkc0loXdPbkOe1nR5w17sXZ5nmYZ6IcA35reexpzB82AF/Mv6JnAjuABCfXeyHmX7v3AWmWP/OAe4B7LNvcB+zHfNY+BZjh5JoTLLXstdTVup/b16wwN305BqQDSU6u2R9zYA9s91if2seYf/gUAU2Yx3fvwHx+6AvgKLAVCLFsmwSsbPe1P7N8pjOBnzq55kzMY9Wtn+fWWWtDgY1n+ww5seY3LZ/TfZhDe0jHmi33z8gXZ9VsefyN1s9wu217tZ9lqQIhhDCovjxEI4QQohck4IUQwqAk4IUQwqAk4IUQwqAk4IUQwqAk4IUQwqAk4IUQwqD+P6tVO+yC6/ZcAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net_slowfast.save_parameters(\"parameters_sf.params\")"
      ],
      "metadata": {
        "id": "Z-M44n955j9g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference1.py --data-list val.txt --model slowfast_4x16_resnet50_custom --slow-temporal-stride 16 --fast-temporal-stride 2 --resume-params parameters_sf.params --num-classes 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erxzsdWu-4RR",
        "outputId": "c16a2420-6c4c-4370-f6d1-0acb8b151d84"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.1` and `torch==1.11.0+cu113` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
            "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n",
            "Namespace(data_aug='v1', data_dir='', data_list='val.txt', dtype='float32', fast_temporal_stride=2, gpu_id=0, hashtag='', input_size=224, log_interval=10, logging_file='predictions.log', mode=None, model='slowfast_4x16_resnet50_custom', need_root=False, new_height=256, new_length=32, new_step=1, new_width=340, num_classes=3, num_crop=1, num_segments=1, resume_params='parameters_sf.params', save_dir='./predictions', save_logits=False, save_preds=False, slow_temporal_stride=16, slowfast=False, ten_crop=False, three_crop=False, use_decord=True, use_pretrained=False, video_loader=True)\n",
            "Pre-trained model parameters_sf.params is successfully loaded.\n",
            "Successfully built model slowfast_4x16_resnet50_custom\n",
            "Load 30 video samples.\n",
            "[05:17:40] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:96: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
            "Traceback (most recent call last):\n",
            "  File \"inference1.py\", line 272, in <module>\n",
            "    main()\n",
            "  File \"inference1.py\", line 233, in main\n",
            "    pred = net(video_input.astype(opt.dtype, copy=False))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mxnet/gluon/block.py\", line 825, in __call__\n",
            "    out = self.forward(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mxnet/gluon/block.py\", line 1502, in forward\n",
            "    return self.hybrid_forward(ndarray, x, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gluoncv/model_zoo/action_recognition/slowfast.py\", line 363, in hybrid_forward\n",
            "    slow = self.SlowPath(F, slow_input, lateral)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gluoncv/model_zoo/action_recognition/slowfast.py\", line 379, in SlowPath\n",
            "    x = self.slow_conv1(x)                          # bx64x4x112x112, input is bx3x4x224x224\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mxnet/gluon/block.py\", line 825, in __call__\n",
            "    out = self.forward(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mxnet/gluon/block.py\", line 1502, in forward\n",
            "    return self.hybrid_forward(ndarray, x, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mxnet/gluon/nn/conv_layers.py\", line 145, in hybrid_forward\n",
            "    act = getattr(F, self._op_name)(x, weight, name='fwd', **self._kwargs)\n",
            "  File \"<string>\", line 169, in Convolution\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mxnet/_ctypes/ndarray.py\", line 91, in _imperative_invoke\n",
            "    ctypes.byref(out_stypes)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mxnet/base.py\", line 246, in check_call\n",
            "    raise get_last_ffi_error()\n",
            "mxnet.base.MXNetError: Traceback (most recent call last):\n",
            "  File \"../include/mxnet/./tuple.h\", line 543\n",
            "MXNetError: Check failed: dim_size_is_known(d[i]): Shape dim size must be known, while received -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing on individual videos"
      ],
      "metadata": {
        "id": "Arh02-m2346Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "from mxnet import gluon, nd, image\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv import utils\n",
        "from gluoncv.model_zoo import get_model"
      ],
      "metadata": {
        "id": "-ndmyb3HauvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "decord = try_import_decord()\n",
        "\n",
        "video_fname = '/content/okutama-112-sitting-47_vRYo7nFf.mp4'\n",
        "vr = decord.VideoReader(video_fname)\n",
        "frame_id_list = range(0, 64, 1)\n",
        "video_data = vr.get_batch(frame_id_list).asnumpy()\n",
        "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]"
      ],
      "metadata": {
        "id": "JHUk4YFBz1Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "clip_input = transform_fn(clip_input)\n",
        "clip_input = np.stack(clip_input, axis=0)\n",
        "clip_input = clip_input.reshape((-1,) + (32, 3, 224, 224))\n",
        "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n",
        "print('Video data is downloaded and preprocessed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlkMiOjQ0Bmm",
        "outputId": "b73f9667-3957-40ca-9ca2-e85a00994e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video data is downloaded and preprocessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'i3d_resnet50_v1_custom'\n",
        "net = get_model(model_name, nclass=3, pretrained=False, classes=['walking','running','sitting'])\n",
        "net.load_parameters('parameters.params')\n",
        "print('%s model is successfully loaded.' % model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHJu7IKW0FH3",
        "outputId": "e91374e4-2e8e-4aef-b94a-b71cc0ba579d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv4_weight is done with shape:  (64, 3, 5, 7, 7)\n",
            "batchnorm4_gamma is done with shape:  (64,)\n",
            "batchnorm4_beta is done with shape:  (64,)\n",
            "batchnorm4_running_mean is done with shape:  (64,)\n",
            "batchnorm4_running_var is done with shape:  (64,)\n",
            "layer1_0_conv0_weight is done with shape:  (64, 64, 3, 1, 1)\n",
            "layer1_0_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_0_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_0_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_0_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_0_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_0_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_0_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_downsample_conv0_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_downsample_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_beta is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer1_downsample_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer1_1_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_1_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_1_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_1_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_1_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_1_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_1_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_1_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer1_2_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\n",
            "layer1_2_batchnorm0_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm0_running_var is done with shape:  (64,)\n",
            "layer1_2_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\n",
            "layer1_2_batchnorm1_gamma is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_beta is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_mean is done with shape:  (64,)\n",
            "layer1_2_batchnorm1_running_var is done with shape:  (64,)\n",
            "layer1_2_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\n",
            "layer1_2_batchnorm2_gamma is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_beta is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_mean is done with shape:  (256,)\n",
            "layer1_2_batchnorm2_running_var is done with shape:  (256,)\n",
            "layer2_0_conv0_weight is done with shape:  (128, 256, 3, 1, 1)\n",
            "layer2_0_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_0_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_0_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_0_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_0_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_0_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_0_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_downsample_conv0_weight is done with shape:  (512, 256, 1, 1, 1)\n",
            "layer2_downsample_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_beta is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer2_downsample_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer2_1_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_1_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_1_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_1_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_1_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_1_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_1_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_1_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_2_conv0_weight is done with shape:  (128, 512, 3, 1, 1)\n",
            "layer2_2_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_2_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_2_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_2_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_2_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_2_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_2_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer2_3_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\n",
            "layer2_3_batchnorm0_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm0_running_var is done with shape:  (128,)\n",
            "layer2_3_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\n",
            "layer2_3_batchnorm1_gamma is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_beta is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_mean is done with shape:  (128,)\n",
            "layer2_3_batchnorm1_running_var is done with shape:  (128,)\n",
            "layer2_3_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\n",
            "layer2_3_batchnorm2_gamma is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_beta is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_mean is done with shape:  (512,)\n",
            "layer2_3_batchnorm2_running_var is done with shape:  (512,)\n",
            "layer3_0_conv0_weight is done with shape:  (256, 512, 3, 1, 1)\n",
            "layer3_0_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_0_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_0_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_0_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_0_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_0_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_0_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_downsample_conv0_weight is done with shape:  (1024, 512, 1, 1, 1)\n",
            "layer3_downsample_batchnorm0_gamma is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_beta is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_mean is done with shape:  (1024,)\n",
            "layer3_downsample_batchnorm0_running_var is done with shape:  (1024,)\n",
            "layer3_1_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_1_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_1_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_1_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_1_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_1_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_1_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_1_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_2_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_2_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_2_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_2_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_2_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_2_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_2_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_2_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_3_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_3_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_3_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_3_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_3_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_3_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_3_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_3_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_4_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\n",
            "layer3_4_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_4_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_4_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_4_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_4_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_4_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_4_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer3_5_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\n",
            "layer3_5_batchnorm0_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm0_running_var is done with shape:  (256,)\n",
            "layer3_5_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\n",
            "layer3_5_batchnorm1_gamma is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_beta is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_mean is done with shape:  (256,)\n",
            "layer3_5_batchnorm1_running_var is done with shape:  (256,)\n",
            "layer3_5_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\n",
            "layer3_5_batchnorm2_gamma is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_beta is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_mean is done with shape:  (1024,)\n",
            "layer3_5_batchnorm2_running_var is done with shape:  (1024,)\n",
            "layer4_0_conv0_weight is done with shape:  (512, 1024, 1, 1, 1)\n",
            "layer4_0_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_0_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_0_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_0_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_0_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_0_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_0_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_downsample_conv0_weight is done with shape:  (2048, 1024, 1, 1, 1)\n",
            "layer4_downsample_batchnorm0_gamma is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_beta is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_mean is done with shape:  (2048,)\n",
            "layer4_downsample_batchnorm0_running_var is done with shape:  (2048,)\n",
            "layer4_1_conv0_weight is done with shape:  (512, 2048, 3, 1, 1)\n",
            "layer4_1_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_1_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_1_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_1_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_1_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_1_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_1_batchnorm2_running_var is done with shape:  (2048,)\n",
            "layer4_2_conv0_weight is done with shape:  (512, 2048, 1, 1, 1)\n",
            "layer4_2_batchnorm0_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm0_running_var is done with shape:  (512,)\n",
            "layer4_2_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\n",
            "layer4_2_batchnorm1_gamma is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_beta is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_mean is done with shape:  (512,)\n",
            "layer4_2_batchnorm1_running_var is done with shape:  (512,)\n",
            "layer4_2_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\n",
            "layer4_2_batchnorm2_gamma is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_beta is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_mean is done with shape:  (2048,)\n",
            "layer4_2_batchnorm2_running_var is done with shape:  (2048,)\n",
            "dense4_weight is skipped with shape:  (3, 2048)\n",
            "dense4_bias is skipped with shape:  (3,)\n",
            "i3d_resnet50_v1_custom model is successfully loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = net(nd.array(clip_input))\n",
        "\n",
        "topK = 3\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (ind[i], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C_AqMOY0V7Z",
        "outputId": "9d89ba34-0c11-46e0-8ff9-e3304cdd37a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input video clip is classified to be\n",
            "\t[\n",
            "[0]\n",
            "<NDArray 1 @cpu(0)>], with probability 0.465.\n",
            "\t[\n",
            "[1]\n",
            "<NDArray 1 @cpu(0)>], with probability 0.347.\n",
            "\t[\n",
            "[2]\n",
            "<NDArray 1 @cpu(0)>], with probability 0.188.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "decord = try_import_decord()\n",
        "\n",
        "video_fname = '/content/okutama-112-sitting-47_vRYo7nFf.mp4'\n",
        "vr = decord.VideoReader(video_fname)\n",
        "frame_id_list_w = range(203, 267, 1)\n",
        "video_data_w = vr.get_batch(frame_id_list_w).asnumpy()\n",
        "clip_input_w = [video_data_w[vid, :, :, :] for vid, _ in enumerate(frame_id_list_w)]"
      ],
      "metadata": {
        "id": "r5Nw0RT50f3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "clip_input_w = transform_fn(clip_input_w)\n",
        "clip_input_w = np.stack(clip_input_w, axis=0)\n",
        "clip_input_w = clip_input_w.reshape((-1,) + (32, 3, 224, 224))\n",
        "clip_input_w = np.transpose(clip_input_w, (0, 2, 1, 3, 4))\n",
        "print('Video data is downloaded and preprocessed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEnwTzk12b4V",
        "outputId": "b4f28f47-6709-4805-ab8c-6c0d8ee32db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video data is downloaded and preprocessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = net(nd.array(clip_input_w))\n",
        "classes = {0:\"walking\", 1: \"running\", 2:\"sitting\"}\n",
        "topK = 3\n",
        "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (classes[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_hkO4352ffe",
        "outputId": "5ee5c0f5-3232-4278-965f-eba4b33a3ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input video clip is classified to be\n",
            "\t[walking], with probability 0.445.\n",
            "\t[running], with probability 0.348.\n",
            "\t[sitting], with probability 0.207.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "decord = try_import_decord()\n",
        "\n",
        "video_fname = '/content/okutama-112-sitting-47_vRYo7nFf.mp4'\n",
        "vr = decord.VideoReader(video_fname)\n",
        "frame_id_list_r = range(406, 470, 1)\n",
        "video_data_r = vr.get_batch(frame_id_list_r).asnumpy()\n",
        "clip_input_r = [video_data_r[vid, :, :, :] for vid, _ in enumerate(frame_id_list_r)]"
      ],
      "metadata": {
        "id": "OG7B6ePJ2krc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "clip_input_r = transform_fn(clip_input_r)\n",
        "clip_input_r = np.stack(clip_input_r, axis=0)\n",
        "clip_input_r = clip_input_r.reshape((-1,) + (32, 3, 224, 224))\n",
        "clip_input_r = np.transpose(clip_input_r, (0, 2, 1, 3, 4))\n",
        "print('Video data is downloaded and preprocessed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfg_0QYJ5EeV",
        "outputId": "3fc5b0ec-2e4e-423f-9ee6-fe5ebf233a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video data is downloaded and preprocessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gluoncv.utils.filesystem import try_import_decord\n",
        "decord = try_import_decord()\n",
        "\n",
        "video_fname = '/content/okutama-112-sitting-47_vRYo7nFf.mp4'\n",
        "vr = decord.VideoReader(video_fname)\n",
        "frame_id_list_s = range(87, 151, 1)\n",
        "video_data_s = vr.get_batch(frame_id_list_s).asnumpy()\n",
        "clip_input_s = [video_data_s[vid, :, :, :] for vid, _ in enumerate(frame_id_list_s)]"
      ],
      "metadata": {
        "id": "5sFn4Gxt5lzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "clip_input_s = transform_fn(clip_input_s)\n",
        "clip_input_s = np.stack(clip_input_s, axis=0)\n",
        "clip_input_s = clip_input_s.reshape((-1,) + (32, 3, 224, 224))\n",
        "clip_input_s = np.transpose(clip_input_s, (0, 2, 1, 3, 4))\n",
        "print('Video data is downloaded and preprocessed.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnQaBagJ58--",
        "outputId": "b1d2dafc-1d24-4297-e81e-177a766a029d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video data is downloaded and preprocessed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predw = net(nd.array(clip_input_w))\n",
        "predr = net(nd.array(clip_input_r))\n",
        "preds = net(nd.array(clip_input_s))\n",
        "classes = {0:\"walking\", 1: \"running\", 2:\"sitting\"}\n",
        "topK = 3\n",
        "indw = nd.topk(predw, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (classes[indw[i].asscalar()], nd.softmax(predw)[0][indw[i]].asscalar()))\n",
        "    \n",
        "indr = nd.topk(predr, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (classes[indr[i].asscalar()], nd.softmax(predr)[0][indr[i]].asscalar()))\n",
        "    \n",
        "inds = nd.topk(preds, k=topK)[0].astype('int')\n",
        "print('The input video clip is classified to be')\n",
        "for i in range(topK):\n",
        "    print('\\t[%s], with probability %.3f.'%\n",
        "          (classes[inds[i].asscalar()], nd.softmax(preds)[0][inds[i]].asscalar()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i74eLBRE6Dis",
        "outputId": "e1610d48-bd86-4a6a-e274-9250274d27f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input video clip is classified to be\n",
            "\t[walking], with probability 0.464.\n",
            "\t[running], with probability 0.337.\n",
            "\t[sitting], with probability 0.199.\n",
            "The input video clip is classified to be\n",
            "\t[sitting], with probability 0.933.\n",
            "\t[walking], with probability 0.034.\n",
            "\t[running], with probability 0.033.\n",
            "The input video clip is classified to be\n",
            "\t[walking], with probability 0.587.\n",
            "\t[running], with probability 0.305.\n",
            "\t[sitting], with probability 0.108.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "11yWHsxU6KRS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "I3D model ",
      "provenance": [],
      "mount_file_id": "1pwIidXtuWmAuP3ML22PTyhKumOKYD9TJ",
      "authorship_tag": "ABX9TyP6S7yNOJBeI/n+a88zpvdc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}